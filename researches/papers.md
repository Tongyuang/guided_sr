Papers
======

A list of related papers.

## [Invertible Image Rescaling](https://link.springer.com/chapter/10.1007/978-3-030-58452-8_8), ECCV 2020, IJCV 2022 PKU+MSRA

Code [here](https://github.com/pkuxmq/Invertible-Image-Rescaling)

#### Abstract
- typical image downscaling is a **non-injective mapping** due to the loss of high-frequency information.
- Simply upscaling with image super-resolution methods results in unsatisfactory recovering performance.
- Invertible Rescaling Net (IRN) produces visually-pleasing low-resolution images and meanwhile capture the distribution of the lost information using a latent variable
- upscaling is made tractable by inversely passing a randomly-drawn latent variable with the low-resolution image through the network.

#### Related Work
**Difference from SR**. Note that image upscaling is a different task from superresolution. In our scenario, the ground-truth HR image is available at the beginning but somehow we have to discard it and store/transmit the LR version instead.

**Image Compression Methods** Image compression may be lossy (e.g., JPEG, BPG) or lossless (e.g., PNG, BMP). Also deep learning related methods.

#### Model

<img src="https://raw.githubusercontent.com/pkuxmq/Invertible-Image-Rescaling/master/figures/architecture.jpg">

1. **Haar Transformation**: From original image($H\times W \times C$) to filtered information ($\frac{1}{2}H \times \frac{1}{2}W \times 4C$), the first channel is the low frequency information and the remaining 3 channels are the high frequency residual components in 3 directions.

2. **Inv Block** to produce more representative high frequency information.

3. **Quantization** converts floating-point values of produced LR images to 8-bit unsigned int. The quantization module is nondifferentiable, use Straight-Through Estimator to mitigate this.

#### Training Objective

1. **LR Guidance** - to make the generated low resolution image easy to read.
$$L_{guide}(\theta) = \sum_{n=1}^{N} l_y(y_{guide}^{(n)},f_{\theta}^{y}(x^{(n)}))$$

$y_{guide}^{(n)}$ is generated by Bicubic method and $l_y$ is any kind of loss.

2. **HR Reconstruction**

$$L_{recon}(θ) = \sum_{n=1}^{N}E_{p(z)}[l_{\chi}(x^{(n)},f_{(\theta)}^{-1}(f_{\theta}^{y}(x^{(n)}),z)]$$

Introduces a case-agnostic $z$ that follows the distribution $p(z)$, the upscale function $f_{(\theta)}^{-1}$ takes both the downscaled image and a latent variable to generate the original image.

3. **Distribution Matching** encourage the model to catch the data distribution q(x) of HR images

4. Total loss:

$$L_{total} := λ_1L_{recon} + λ_2L_{guide} + λ_3L_{distr}$$

To solve the unstable issues, use this instead:

$$L_{total} := λ_1L_{recon} + λ_2L_{guide} + λ'_3L_{distr}$$

refer to the original paper to check the meaning of $λ'$.

## 2.[Enhancing Image Rescaling using Dual Latent Variables in Invertible Neural Network](https://arxiv.org/abs/2207.11844), CVPR 2022, USC+Baidu

#### Abstract
- The ill-posed nature of **image downscaling**, where one HR image could be downsized to multiple LR images depending on different interpolation kernels and resampling methods, is not considered. 
- **A new downscaling latent variable**, in addition to the original one representing uncertainties in image upscaling, is introduced to model variations in the image downscaling process.


## 3. [Downscaled Representation Matters: Improving Image Rescaling with Collaborative Downscaled Images](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html), ICCV 2023

Code [here](https://github.com/xubingna/HCD)


## 4.[Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling](https://arxiv.org/abs/2303.02353), AAAI 2023, Bytedance

Code [here](https://github.com/yang-jin-hai/SAIN)

