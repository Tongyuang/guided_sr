Papers
======

A list of related papers.

## [Invertible Image Rescaling](https://link.springer.com/chapter/10.1007/978-3-030-58452-8_8), ECCV 2020

Code [here](https://github.com/pkuxmq/Invertible-Image-Rescaling)

#### Abstract
- typical image downscaling is a **non-injective mapping** due to the loss of high-frequency information.
- Simply upscaling with image super-resolution methods results in unsatisfactory recovering performance.
- Invertible Rescaling Net (IRN) produces visually-pleasing low-resolution images and meanwhile capture the distribution of the lost information using a latent variable
- upscaling is made tractable by inversely passing a randomly-drawn latent variable with the low-resolution image through the network.

#### Related Work
**Difference from SR**. Note that image upscaling is a different task from superresolution. In our scenario, the ground-truth HR image is available at the beginning but somehow we have to discard it and store/transmit the LR version instead.

**Image Compression Methods** Image compression may be lossy (e.g., JPEG, BPG) or lossless (e.g., PNG, BMP). Also deep learning related methods.

#### Model

<img src="https://www.researchgate.net/publication/364306204/figure/fig2/AS:11431281089160479@1665454362260/Illustration-of-our-Invertible-Rescaling-Network-IRN-as-the-instantiation-model-of-our.png">

1. **Haar Transformation**: From original image($H\times W \times C$) to filtered information ($\frac{1}{2}H \times \frac{1}{2}W \times 4C$), the first channel is the low frequency information and the remaining 3 channels are the high frequency residual components in 3 directions.

2. **Inv Block** to produce more representative high frequency information.

3. **Quantization** converts floating-point values of produced LR images to 8-bit unsigned int. The quantization module is nondifferentiable, use Straight-Through Estimator to mitigate this.

#### Training Objective

1. **LR Guidance** - to make the generated low resolution image easy to read.
$$L_{guide}(\theta) = \sum_{n=1}^{N} l_y(y_{guide}^{(n)},f_{\theta}^{y}(x^{(n)}))$$

$y_{guide}^{(n)}$ is generated by Bicubic method and $l_y$ is any kind of loss.

2. **HR Reconstruction**

$$L_{recon}(θ) = \sum_{n=1}^{N}E_{p(z)}[l_{\chi}(x^{(n)},f_{(\theta)}^{-1}(f_{\theta}^{y}(x^{(n)}),z)]$$

Introduces a case-agnostic $z$ that follows the distribution $p(z)$, the upscale function $f_{(\theta)}^{-1}$ takes both the downscaled image and a latent variable to generate the original image.

3. **Distribution Matching** encourage the model to catch the data distribution q(x) of HR images

4. Total loss:

$$L_{total} := λ_1L_{recon} + λ_2L_{guide} + λ_3L_{distr}$$

To solve the unstable issues, use this instead:
$$L_{total} := λ_1L_{recon} + λ_2L_{guide} + λ'_3L_{distr}$$
refer to the original paper to check the meaning of $λ'$.



## 2. [Downscaled Representation Matters: Improving Image Rescaling with Collaborative Downscaled Images](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html), ICCV 2023

